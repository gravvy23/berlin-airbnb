{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_initial = pd.read_csv('./input/listings_summary.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 350,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 22552 rows and 96 columns.\n",
      "It contains 0 duplicates.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# checking shape\n",
    "print(\"The dataset has {} rows and {} columns.\".format(*df_initial.shape))\n",
    "\n",
    "# ... and duplicates\n",
    "print(\"It contains {} duplicates.\".format(df_initial.duplicated().sum()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['id', 'listing_url', 'scrape_id', 'last_scraped', 'name', 'summary',\n",
       "       'space', 'description', 'experiences_offered', 'neighborhood_overview',\n",
       "       'notes', 'transit', 'access', 'interaction', 'house_rules',\n",
       "       'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url',\n",
       "       'host_id', 'host_url', 'host_name', 'host_since', 'host_location',\n",
       "       'host_about', 'host_response_time', 'host_response_rate',\n",
       "       'host_acceptance_rate', 'host_is_superhost', 'host_thumbnail_url',\n",
       "       'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n",
       "       'host_total_listings_count', 'host_verifications',\n",
       "       'host_has_profile_pic', 'host_identity_verified', 'street',\n",
       "       'neighbourhood', 'neighbourhood_cleansed',\n",
       "       'neighbourhood_group_cleansed', 'city', 'state', 'zipcode', 'market',\n",
       "       'smart_location', 'country_code', 'country', 'latitude', 'longitude',\n",
       "       'is_location_exact', 'property_type', 'room_type', 'accommodates',\n",
       "       'bathrooms', 'bedrooms', 'beds', 'bed_type', 'amenities', 'square_feet',\n",
       "       'price', 'weekly_price', 'monthly_price', 'security_deposit',\n",
       "       'cleaning_fee', 'guests_included', 'extra_people', 'minimum_nights',\n",
       "       'maximum_nights', 'calendar_updated', 'has_availability',\n",
       "       'availability_30', 'availability_60', 'availability_90',\n",
       "       'availability_365', 'calendar_last_scraped', 'number_of_reviews',\n",
       "       'first_review', 'last_review', 'review_scores_rating',\n",
       "       'review_scores_accuracy', 'review_scores_cleanliness',\n",
       "       'review_scores_checkin', 'review_scores_communication',\n",
       "       'review_scores_location', 'review_scores_value', 'requires_license',\n",
       "       'license', 'jurisdiction_names', 'instant_bookable',\n",
       "       'is_business_travel_ready', 'cancellation_policy',\n",
       "       'require_guest_profile_picture', 'require_guest_phone_verification',\n",
       "       'calculated_host_listings_count', 'reviews_per_month'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 351,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check the columns we currently have\n",
    "df_initial.columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 22552 rows and 31 columns - after dropping irrelevant columns.\n"
     ]
    }
   ],
   "source": [
    "# define the columns we want to keep\n",
    "columns_to_keep = ['id', 'description', 'experiences_offered', 'host_has_profile_pic', 'host_response_rate', 'host_is_superhost', 'host_identity_verified', 'host_listings_count',  'neighbourhood_group_cleansed', \n",
    "                   'latitude', 'longitude', 'property_type', 'room_type', 'accommodates', 'bathrooms',  \n",
    "                   'bedrooms', 'bed_type', 'amenities', 'square_feet', 'price', 'cleaning_fee', 'space',\n",
    "                   'security_deposit', 'guests_included', 'extra_people', 'minimum_nights', 'number_of_reviews', 'review_scores_rating',\n",
    "                   'instant_bookable', 'is_business_travel_ready', 'cancellation_policy',  'reviews_per_month']\n",
    "df_raw = df_initial[columns_to_keep].set_index('id')\n",
    "print(\"The dataset has {} rows and {} columns - after dropping irrelevant columns.\".format(*df_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cleaning price columns \n",
    "\n",
    "# checking Nan's in \"price\" column\n",
    "df_raw.price.isna().sum()\n",
    "\n",
    "# Nan's in \"cleaning_fee\" column\n",
    "df_raw.cleaning_fee.isna().sum()\n",
    "#There are plenty of Nan's. It's more than likely that these hosts do not charge any extra cleaning fee. \n",
    "#So let's simply replace these null values with $0.00\n",
    "df_raw.cleaning_fee = df_raw.cleaning_fee.fillna('$0.00')\n",
    "\n",
    "#The same is true for the security_deposit\n",
    "df_raw.security_deposit.isna().sum()\n",
    "df_raw.security_deposit = df_raw.security_deposit.fillna('$0.00')\n",
    "\n",
    "# checking Nan's in \"extra_people\" column\n",
    "df_raw.extra_people.isna().sum()\n",
    "\n",
    "#Let's remove the dollar signs in all four columns and convert the string values into numerical ones:\n",
    "df_raw.price = df_raw.price.str.replace('$', '').str.replace(',', '').astype(float)\n",
    "df_raw.cleaning_fee = df_raw.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float)\n",
    "df_raw.security_deposit = df_raw.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\n",
    "df_raw.extra_people = df_raw.extra_people.str.replace('$', '').str.replace(',', '').astype(float)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {},
   "outputs": [],
   "source": [
    "#removing outliers from \"price\" column\n",
    "price_statistics = df_raw.price.describe()\n",
    "df_raw = df_raw.drop(df_raw[abs(df_raw.price - price_statistics[\"mean\"]) > 3*price_statistics[\"std\"]].index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dealing with NaN's\n",
    "df_raw.isna().sum()\n",
    "\n",
    "# drop columns with too many Nan's\n",
    "df_raw.drop(columns=['square_feet', 'space', 'host_response_rate'], inplace=True)\n",
    "\n",
    "#droping rows with reviews, bathrooms and bedrooms as NaN - I think that those are too imnportant to drop \n",
    "df_raw.dropna(subset=[\"review_scores_rating\", \"bathrooms\", \"bedrooms\"], inplace=True)\n",
    "\n",
    "# replace host connected columns Nan's with no or 0\n",
    "df_raw.host_has_profile_pic = df_raw.host_has_profile_pic.fillna(value='f')\n",
    "df_raw.host_is_superhost = df_raw.host_is_superhost.fillna(value='f')\n",
    "df_raw.host_identity_verified = df_raw.host_identity_verified.fillna(value='f')\n",
    "df_raw.host_listings_count = df_raw.host_listings_count.fillna(value=0)\n",
    "\n",
    "#dropping \"experiences_offered\" column cause all values are \"none\"\n",
    "df_raw.experiences_offered.unique()\n",
    "df_raw.drop(columns=['experiences_offered'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dataset has 18107 rows and 27 columns - after having dealt with missing values.\n"
     ]
    }
   ],
   "source": [
    "print(\"The dataset has {} rows and {} columns - after having dealt with missing values.\".format(*df_raw.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Distance to Centroid of Berlin\n",
    "# adding new column \"distance\" distance to Berlin Centre \n",
    "from geopy.distance import great_circle\n",
    "def distance_to_mid(lat, lon):\n",
    "    berlin_centre = (52.5027778, 13.404166666666667)\n",
    "    accommodation = (lat, lon)\n",
    "    return great_circle(berlin_centre, accommodation).km\n",
    "df_raw['distance'] = df_raw.apply(lambda x: distance_to_mid(x.latitude, x.longitude), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NaNs in size_column absolute:      9153\n",
      "NaNs in size_column in percentage: 0.505 %\n"
     ]
    }
   ],
   "source": [
    "#Lodging size \n",
    "\n",
    "#One of the most important pieces of information for predicting the rate is the size. \n",
    "#Since the column square_feet was heavily filled with null values\n",
    "#Let's check, if the column description reveals any information about size instead\n",
    "df_raw.description.isna().sum()\n",
    "# extract numbers \n",
    "df_raw['size'] = df_raw['description'].str.extract('(\\d{2,3}\\s?[smSM])', expand=True)\n",
    "df_raw['size'] = df_raw['size'].str.replace(\"\\D\", \"\")\n",
    "# change datatype of size into float\n",
    "df_raw['size'] = df_raw['size'].astype(float)\n",
    "print('NaNs in size_column absolute:     ', df_raw['size'].isna().sum())\n",
    "print('NaNs in size_column in percentage:', round(df_raw['size'].isna().sum()/len(df_raw),3), '%')\n",
    "# drop description column\n",
    "df_raw.drop(['description'], axis=1, inplace=True)\n",
    "#Predicting missing values with regression\n",
    "# filter out sub_df to work with\n",
    "sub_df = df_raw[['accommodates', 'bathrooms', 'bedrooms',  'price', 'cleaning_fee', \n",
    "                 'security_deposit', 'extra_people', 'guests_included', 'distance', 'size', 'review_scores_rating']]\n",
    "# split datasets\n",
    "train_data = sub_df[sub_df['size'].notnull()]\n",
    "test_data  = sub_df[sub_df['size'].isnull()]\n",
    "\n",
    "# define X\n",
    "X_train = train_data.drop('size', axis=1)\n",
    "X_test  = test_data.drop('size', axis=1)\n",
    "\n",
    "# define y\n",
    "y_train = train_data['size']\n",
    "\n",
    "# import Linear Regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# instantiate\n",
    "linreg = LinearRegression()\n",
    "\n",
    "# fit model to training data\n",
    "linreg.fit(X_train, y_train)\n",
    "\n",
    "# making predictions\n",
    "y_test = linreg.predict(X_test)\n",
    "y_test = pd.DataFrame(y_test)\n",
    "y_test.columns = ['size']\n",
    "\n",
    "# make the index of X_test to an own dataframe\n",
    "prelim_index = pd.DataFrame(X_test.index)\n",
    "prelim_index.columns = ['prelim']\n",
    "\n",
    "# ... and concat this dataframe with y_test\n",
    "y_test = pd.concat([y_test, prelim_index], axis=1)\n",
    "y_test.set_index(['prelim'], inplace=True)\n",
    "new_test_data = pd.concat([X_test, y_test], axis=1)\n",
    "# combine train and test data back to a new sub df\n",
    "cols = train_data.columns.tolist()\n",
    "cols = cols[:-2] + cols[-1:] + cols[-2:-1]\n",
    "train_data = train_data[cols]\n",
    "sub_df_new = pd.concat([new_test_data, train_data], axis=0)\n",
    "# prepare the multiple columns before concatening\n",
    "df_raw.drop(['accommodates', 'bathrooms', 'bedrooms',  'price', 'cleaning_fee', \n",
    "                 'security_deposit', 'extra_people', 'guests_included', 'distance', 'size', 'review_scores_rating'], \n",
    "            axis=1, inplace=True)\n",
    "# concate back to complete dataframe\n",
    "df = pd.concat([sub_df_new, df_raw], axis=1)\n",
    "#To be on the safe side, let’s remove all outliers\n",
    "size_statistics = df[\"size\"].describe()\n",
    "df = df.drop(df[abs(df[\"size\"]- size_statistics[\"mean\"]) > 3*size_statistics[\"std\"]].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 370,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split berlin into sectors \n",
    "east_berlin = ['Mitte', 'Pankow', 'Friedrichshain-Kreuzberg', 'Treptow - Köpenick', 'Lichtenberg', 'Marzahn - Hellersdorf']\n",
    "west_berlin = ['Tempelhof - Schöneberg', 'Charlottenburg-Wilm.', 'Neukölln', 'Steglitz - Zehlendorf', 'Reinickendorf', 'Spandau']\n",
    "df[\"is_in_east_berlin\"] = df.neighbourhood_group_cleansed.isin(east_berlin)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 375,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Replace strings with booleans\n",
    "df.replace('t', True, inplace=True)\n",
    "df.replace('f', False, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "accommodates                      int64\n",
       "bathrooms                       float64\n",
       "bedrooms                        float64\n",
       "price                           float64\n",
       "cleaning_fee                    float64\n",
       "security_deposit                float64\n",
       "extra_people                    float64\n",
       "guests_included                   int64\n",
       "distance                        float64\n",
       "review_scores_rating            float64\n",
       "size                            float64\n",
       "host_has_profile_pic               bool\n",
       "host_is_superhost                  bool\n",
       "host_identity_verified             bool\n",
       "host_listings_count             float64\n",
       "neighbourhood_group_cleansed     object\n",
       "latitude                        float64\n",
       "longitude                       float64\n",
       "property_type                    object\n",
       "room_type                        object\n",
       "bed_type                         object\n",
       "amenities                        object\n",
       "minimum_nights                    int64\n",
       "number_of_reviews                 int64\n",
       "instant_bookable                   bool\n",
       "is_business_travel_ready           bool\n",
       "cancellation_policy              object\n",
       "reviews_per_month               float64\n",
       "is_in_east_berlin                  bool\n",
       "dtype: object"
      ]
     },
     "execution_count": 376,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
